<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Where&#39;s Waldo: A Study in Image Processing and Recognition by NickyGertman</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Where&#39;s Waldo: A Study in Image Processing and Recognition</h1>
      <h2 class="project-tagline"></h2>
      <a href="https://github.com/NickyGertman/Website" class="btn">View on GitHub</a>
      <a href="https://github.com/NickyGertman/Website/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/NickyGertman/Website/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="who-is-waldo-and-why-do-i-want-to-find-him" class="anchor" href="#who-is-waldo-and-why-do-i-want-to-find-him" aria-hidden="true"><span class="octicon octicon-link"></span></a>Who is Waldo and why do I want to find him?</h1>

<p>Where's Waldo is a children's picture game invented by Martin Handford. The game involves a large image filled with various characters and funny situations. The reader is supposed to search through the image in order to find Waldo, who can always be found wearing a red and white polo, glasses, and a bobble hat. The image usually contains a few characters who look an awful lot like Waldo, but are only meant to trick the reader. [1]
<img src="https://cloud.githubusercontent.com/assets/15268123/11768783/54557c38-a18c-11e5-81dc-0d702c9d569b.jpg" alt="WheresWaldo">
<em>Figure 1: Unmodified Where's Waldo puzzle</em></p>

<h1>
<a id="this-project-will-compare-two-separate-approaches-to-finding-waldo-in-the-famous-picture-game-wheres-waldo" class="anchor" href="#this-project-will-compare-two-separate-approaches-to-finding-waldo-in-the-famous-picture-game-wheres-waldo" aria-hidden="true"><span class="octicon octicon-link"></span></a>This project will compare two separate approaches to finding Waldo in the famous picture game, Where's Waldo.</h1>

<h3>
<a id="first-approach" class="anchor" href="#first-approach" aria-hidden="true"><span class="octicon octicon-link"></span></a>First Approach</h3>

<p>The first approach utilizes color channels to track down Waldo. The first step is to take an image's red channel and filter out all non-red colors. This will leave behind only the reds in the image as seen in Figure 2. The black areas indicate that the area was red in the original image.  <img src="https://cloud.githubusercontent.com/assets/15268123/11768803/e82d49e0-a18c-11e5-8f84-43a03171c01a.jpg" alt="Reds only"> <em>Figure 2: Red channel filter applied to Where's Waldo puzzle</em></p>

<p>Then I created a white channel filter and applied it to the original image. I combined these two filtered results in order to identify areas that contained both red and white. This combination is shown in Figure 3. In this image, everything red and white is displayed in white and everything else appears black: 
<img src="https://cloud.githubusercontent.com/assets/15268123/11768826/9975e0a4-a18d-11e5-94e9-af049eb52040.jpg" alt="redsAndWhites"> <em>Figure 3: Red and white channel of Where's Waldo puzzle</em></p>

<p>Finally, I apply the combined red and white filter to the original image and circle the positive results as displayed in Figure 4. Clearly, this contains far too many false positives. However, it does correctly identify Waldo at the very least. <a href="https://github.com/NickyGertman/Website/blob/master/RedChannel.py">View this code here.</a>
<img src="https://cloud.githubusercontent.com/assets/15268123/11768890/6fb97e54-a18f-11e5-8158-47e45a37a585.jpg" alt="results"> <em>Figure 4: Final image with circled areas found to contain Waldo by the algorithm</em></p>

<h3>
<a id="second-approach" class="anchor" href="#second-approach" aria-hidden="true"><span class="octicon octicon-link"></span></a>Second Approach</h3>

<p>The second approach involves machine learning. I will use a Neural Network to study the images of characters that are and are not Waldo to train the computer. In order to accomplish this, I first had to find Waldo by hand in 25 different puzzles. Then, I normalized the face data by cropping each of Waldo's faces to be 50x50 pixels. In order to give the computer an example of 'non-Waldo' faces, I used the same process to create 25 face images from the game that were not Waldo. Here are two example training images:</p>

<p>                                                                    <img src="https://cloud.githubusercontent.com/assets/15268123/11772081/63b30722-a1cd-11e5-8eeb-1b21501d3b62.jpg" alt="Waldo">          <img src="https://cloud.githubusercontent.com/assets/15268123/11772084/6e0dd346-a1cd-11e5-84fc-05cb607ada14.jpg" alt="not Waldo"></p>

<p>The actual training process involves using these images as the X-values in a function, and assigning the Y-values as whether the image is Waldo or not. Waldo images are assigned a Y-value of 1 (for true) and non-Waldo images are assigned a Y-value of 0 (for false). Once all of these values are assigned, I use a subset of the images to train a classifier. The classifier has a fit function that  takes the X and Y values and finds the correlation between the two. The correlation is then applied to future 'predictions' - when I test the function by giving it an image and having it detect whether the image is Waldo or not. </p>

<p>Choosing the correct type of classifier proved to be the most difficult aspect of this approach. I tried various training classifiers from the scikit-learn python library in an effort to improve the accuracy of the predictions the machine was making. In order to compare the results between different classifiers, I created multiple versions of the learning algorithm,  The classifiers I used were: <a href="https://github.com/NickyGertman/Website/blob/master/KNearestNeighbors">K-Nearest Neighbors</a>, <a href="https://github.com/NickyGertman/Website/blob/master/NeuralNetwork.py">General Neural Network</a>, <a href="https://github.com/NickyGertman/Website/blob/master/NaiveBayes">Naive Bayes</a>, <a href="https://github.com/NickyGertman/Website/blob/master/PCAandSVM">Support Vector Machine</a> (SVM), and finally <a href="https://github.com/NickyGertman/Website/blob/master/AdaBoost-SAMME">AdaBoost-SAMME</a>. Figure 5 demonstrates the portion of the neural network that I was working to find: the hidden layer.</p>

<p><img src="https://cloud.githubusercontent.com/assets/15268123/11772277/cb581f78-a1cf-11e5-9ecd-0bde8b4e2516.JPG" alt="Neural Network"> </p>

<p><em>Figure 5: Neural network flow-map [2]</em></p>

<p>Classifiers Used:</p>

<ul>
<li>K-Nearest Neighbor classifies an image by comparing it to its "nearest neighbors" and assigning the classification that matches the majority of its k neighbors [3]. </li>
<li>The general neural network classifier from scikit-learn is "known as unsupervised pre-training" and 
"tries to maximize the likelihood of the data using a particular graphical model."[4] </li>
<li>Naive Bayes method is a "set of supervised learning algorithms based on applying Bayes’ theorem with the 'naive' assumption of independence between every pair of features".[5] </li>
<li>SVM is a supervised learning approach that "builds a model that assigns new examples into one category or the other"[6]. </li>
<li>AdaBoost-SAMME makes multiple passes over the training data. It will come up with a preliminary 'fit' function and then pass over the data again to test it out. It then changes its weights based on the incorrect predictions in order to make it more accurate. [7]</li>
</ul>

<p>These different classification functions had interesting results for their predictions. The Naive Bayes approach was by far the worst. I ran this version multiple times with multiple sizes of partitions of my data, and on average, it was only 40% accurate (Note: random classification is 50% accurate, so this is very bad.)</p>

<p>Then, I ran the generic NN, K-Nearest Neighbors, and SVM classifiers. Surprisingly, these three different methods all had similar results to each other. I ran these versions multiple times with multiple sizes of partitions of my data, and on average, they were each about 50% accurate (still not good, but better than before).</p>

<p>Finally, I was able to test the AdaBoost-SAMME algorithm. I performed testing on this method multiple times and with multiple data sets and, on average, I got about 60% accuracy. This is by no means a great triumph in the world of Artificial Intelligence, but it was better than any of the other classifiers I had tried. </p>

<p>The accuracy of the different classifiers is visualized in Figure 6. </p>

<p>                                    <img src="https://cloud.githubusercontent.com/assets/15268123/11771697/d38f7d3c-a1c8-11e5-9c8a-64c5b5c34225.JPG" alt="chart"></p>

<p><em>Figure 6: Rate of correct Waldo predictions according to different classifiers</em></p>

<p>One thing that probably would have improved the overall results of this research project would have been to increase the size of my data set. More images would have improved the training of the classifiers and would improve their classification results. I hope to be able to find more data in the future and possibly improve upon this work. </p>

<p>This project was completed in a one semester Artificial Intelligence class. Although the experiment did not have the results I had been hoping for, I do feel that it was a very educational and interesting project. </p>

<h3>
<a id="sources" class="anchor" href="#sources" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sources:</h3>

<p>[1] <a href="https://en.wikipedia.org/wiki/Where's_Wally%3F">https://en.wikipedia.org/wiki/Where's_Wally%3F</a></p>

<p>[2] <a href="http://www.texample.net/tikz/examples/neural-network/">http://www.texample.net/tikz/examples/neural-network/</a></p>

<p>[3] <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm</a></p>

<p>[4] <a href="http://scikit-learn.org/stable/modules/neural_networks.html">http://scikit-learn.org/stable/modules/neural_networks.html</a></p>

<p>[5] <a href="http://scikit-learn.org/stable/modules/naive_bayes.html">http://scikit-learn.org/stable/modules/naive_bayes.html</a></p>

<p>[6] <a href="https://en.wikipedia.org/wiki/Support_vector_machine#Support_Vector_Clustering_.28SVC.29">https://en.wikipedia.org/wiki/Support_vector_machine#Support_Vector_Clustering_.28SVC.29</a></p>

<p>[7] <a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier">http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier</a></p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/NickyGertman/Website">Where&#39;s Waldo: A Study in Image Processing and Recognition</a> is maintained by <a href="https://github.com/NickyGertman">NickyGertman</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
