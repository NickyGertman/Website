__author__ = 'nicky'

# inspired by: http://scikit-learn.org/dev/auto_examples/applications/face_recognition.html
# and http://iamtrask.github.io/2015/07/12/basic-python-network/


import numpy as np
from sklearn import ensemble
from PIL import Image


imageArray = np.array([])
isWaldoArray = np.array([])

#Build up the training list
#Go through the sample images and assign them their x values (pixel array values) and their Y values (0 or 1)
#The images are already all cropped to be 50x50 px
for i in range (1,26):
    img = Image.open('TrainingImages/Waldo/waldo' + i.__str__() + '.jpg')

    #in order to use the image as numerical data, we need to convert it to a numpy array
    imageArray = np.append(imageArray, np.asarray(img, dtype=np.uint8)) #convert the image to a numpy array of pixels
    isWaldoArray = np.append(isWaldoArray,1) #Waldo's faces get assigned a true valuation
    img = Image.open('TrainingImages/Not_Waldo/notWaldo' + i.__str__()+ '.jpg')

    #in order to use the image as numerical data, we need to convert it to a numpy array
    imageArray = np.append(imageArray, np.asarray(img, dtype=np.uint8)) #convert the image to a numpy array of pixels
    isWaldoArray = np.append(isWaldoArray,0) #non Waldo faces get assigned a false valuation

#print 'Calculating using 40 images as training...'
imageArray = np.reshape(imageArray, (isWaldoArray.shape[0], -1))

#training classifier
trainingClassifier = ensemble.AdaBoostClassifier()    #This is based off the AdaBoost-SAMME algorithm in which a fit classifier is applied to the 
                                                      #dataset orignially and then it goes back over a copy of the data set and adjusts the weights 
                                                      #of the wrong cases until the data fits more nicely.

trainImages = imageArray[:40]       #An array of the images used to train the machine (first 40 pictures)
trainResults = isWaldoArray[:40]    #Array of the correct results: 0 (not waldo) or 1 (waldo) (first 40 results)

trainingClassifier.fit(trainImages, trainResults) #use built in fit function to classify these results to use later

testImages = imageArray[40:]        #An array of the images used to test the machine (last 10 pictures)
expectedResults = isWaldoArray[40:] #An array of the correct results of the images being tested

testingOutput = trainingClassifier.predict(testImages)

totalPredictions = 10.0
correctPredictions = 0

#go through the results and count all the correct predictions
for i in range(0, len(expectedResults)):
    if expectedResults[i] == testingOutput[i]:
        correctPredictions += 1

score = correctPredictions/totalPredictions * 100
print str(testingOutput)
print '\tAccuracy of Predictions: ' + str(score) + '%'
'''
print 'Calculating K Fold Cross Validation...'
kFold = cross_validation.StratifiedKFold(isWaldoArray, 10)
for train_index, test_index in kFold:
        X_train, X_test = imageArray[train_index], imageArray[test_index]
        Y_train = isWaldoArray[train_index]
        Y_test = isWaldoArray[test_index]


# .. dimension reduction ..

pca = decomposition.RandomizedPCA(whiten=True)
pca.fit(X_train)
X_train_pca = pca.transform(X_train)
X_test_pca = pca.transform(X_test)

# training classification
trainingClassifier = svm.SVC(C=5., gamma=0.00001)
trainingClassifier.fit(X_train_pca, Y_train)
res = trainingClassifier.predict(X_test_pca)
correctPredictions = 0


totalPredictions = 4.0
correctPredictions = 0

for i in range(0, len(res)):
    if res[i] == Y_test[i]:
        correctPredictions += 1

score = correctPredictions/totalPredictions * 100

print '\tAccuracy of Predictions: ' + str(score) + '%'
print 'Results' + str(res)
print 'Expected' + str(Y_test)
'''





